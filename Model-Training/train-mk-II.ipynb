{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devasy23/FaceRec/blob/feature-triplet-loss-function/Model-Training/train-mk-II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other"
      ],
      "metadata": {
        "id": "UCphS8U4-vbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBIYjBF5gXOA",
        "outputId": "c9bfed4e-bae7-4018-9afb-0ea4c0de40db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/611.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m501.8/611.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aszCsokffzYJ",
        "outputId": "1ae4b39b-7aba-4b90-e2eb-34907ecb56d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow_addons.losses import TripletSemiHardLoss\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fQr-_0S-fzYM"
      },
      "outputs": [],
      "source": [
        "class DynamicUnfreezeCallback(Callback):\n",
        "    def __init__(self, model, initial_unfreeze_layers, step_unfreeze_layers, threshold, patience):\n",
        "        super(DynamicUnfreezeCallback, self).__init__()\n",
        "        self.model = model\n",
        "        self.initial_unfreeze_layers = initial_unfreeze_layers\n",
        "        self.step_unfreeze_layers = step_unfreeze_layers\n",
        "        self.threshold = threshold\n",
        "        self.patience = patience\n",
        "        self.best_val_accuracy = 0.0\n",
        "        self.unfreeze_count = initial_unfreeze_layers\n",
        "        self.wait = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_accuracy = logs.get('val_accuracy')\n",
        "\n",
        "        if val_accuracy > self.best_val_accuracy:\n",
        "            self.best_val_accuracy = val_accuracy\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "\n",
        "        if self.best_val_accuracy >= self.threshold and self.wait >= self.patience:\n",
        "            self.wait = 0\n",
        "            self.unfreeze_count += self.step_unfreeze_layers\n",
        "            print(f\"Unfreezing additional {self.step_unfreeze_layers} layers.\")\n",
        "            self.unfreeze_layers(self.unfreeze_count)\n",
        "            self.model.compile(optimizer=Adam(1e-4), loss=TripletSemiHardLoss())\n",
        "\n",
        "    def unfreeze_layers(self, num_layers):\n",
        "        for layer in self.model.layers[-num_layers:]:\n",
        "            layer.trainable = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s9tELCFfzYN",
        "outputId": "5b2cc6ed-f969-485b-9b57-394f12f43cc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219055592/219055592 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "def create_model():\n",
        "    base_model = tf.keras.applications.InceptionResNetV2(input_shape=(160, 160, 3), include_top=False, pooling='avg')\n",
        "\n",
        "    x = base_model.output\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "    x = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "    # Freeze all layers initially\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Unfreeze the last `initial_unfreeze_layers` layers\n",
        "    initial_unfreeze_layers = 10\n",
        "    for layer in model.layers[-initial_unfreeze_layers:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.compile(optimizer=Adam(1e-4), loss=TripletSemiHardLoss())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cqwIShYfzYO"
      },
      "outputs": [],
      "source": [
        "# Dummy data generators for demonstration\n",
        "def generate_triplet(batch_size=32):\n",
        "    while True:\n",
        "        # Generate dummy data\n",
        "        anchor = np.random.rand(batch_size, 160, 160, 3)\n",
        "        positive = np.random.rand(batch_size, 160, 160, 3)\n",
        "        negative = np.random.rand(batch_size, 160, 160, 3)\n",
        "        yield [anchor, positive, negative], np.ones(batch_size)\n",
        "\n",
        "train_generator = generate_triplet()\n",
        "val_generator = generate_triplet()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsytmszufzYP"
      },
      "outputs": [],
      "source": [
        "initial_unfreeze_layers = 10\n",
        "step_unfreeze_layers = 5\n",
        "accuracy_threshold = 0.90\n",
        "patience = 3\n",
        "\n",
        "callbacks = [DynamicUnfreezeCallback(model, initial_unfreeze_layers, step_unfreeze_layers, accuracy_threshold, patience)]\n",
        "\n",
        "model.fit(train_generator,\n",
        "          epochs=50,\n",
        "          steps_per_epoch=100,\n",
        "          validation_data=val_generator,\n",
        "          validation_steps=10,\n",
        "          callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hyEEV4HhfzYP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def generate_triplet(data, labels, batch_size=32):\n",
        "    \"\"\"\n",
        "    Generate batches of triplet samples (anchor, positive, negative).\n",
        "\n",
        "    Args:\n",
        "    data: A numpy array of images.\n",
        "    labels: A numpy array of labels corresponding to the images.\n",
        "    batch_size: Number of triplets to generate in each batch.\n",
        "\n",
        "    Yields:\n",
        "    A tuple (inputs, targets), where:\n",
        "    - inputs is a list containing [anchor, positive, negative] images.\n",
        "    - targets is an array of ones, used for the triplet loss function.\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        anchor_images = []\n",
        "        positive_images = []\n",
        "        negative_images = []\n",
        "\n",
        "        for _ in range(batch_size):\n",
        "            # Randomly select an anchor-positive pair\n",
        "            idx = np.random.randint(0, len(data))\n",
        "            anchor_image = data[idx]\n",
        "            anchor_label = labels[idx]\n",
        "\n",
        "            # Find positive example (same class as anchor)\n",
        "            pos_idx = np.random.choice(np.where(labels == anchor_label)[0])\n",
        "            positive_image = data[pos_idx]\n",
        "\n",
        "            # Find negative example (different class from anchor)\n",
        "            neg_idx = np.random.choice(np.where(labels != anchor_label)[0])\n",
        "            negative_image = data[neg_idx]\n",
        "\n",
        "            # Append the images to their respective lists\n",
        "            anchor_images.append(anchor_image)\n",
        "            positive_images.append(positive_image)\n",
        "            negative_images.append(negative_image)\n",
        "\n",
        "        # Convert lists to numpy arrays\n",
        "        anchor_images = np.array(anchor_images)\n",
        "        positive_images = np.array(positive_images)\n",
        "        negative_images = np.array(negative_images)\n",
        "\n",
        "        # Yield a batch of triplet samples and dummy targets\n",
        "        yield [anchor_images, positive_images, negative_images], np.ones(batch_size)\n",
        "\n",
        "# Example usage\n",
        "# Assuming `data` is an array of images and `labels` is an array of corresponding labels\n",
        "# data = np.array([...])\n",
        "# labels = np.array([...])\n",
        "\n",
        "# Create a generator\n",
        "# train_generator = generate_triplet(data, labels, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQzkLEL-fzYQ"
      },
      "source": [
        "## New RESPONSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DvvJn29UfzYS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c4gJ1Y4KfzYS"
      },
      "outputs": [],
      "source": [
        "def load_image(image_path, target_size):\n",
        "    \"\"\"\n",
        "    Load an image from a file and resize it to the target size.\n",
        "\n",
        "    Args:\n",
        "    image_path (str): Path to the image file.\n",
        "    target_size (tuple): Desired image size (width, height).\n",
        "\n",
        "    Returns:\n",
        "    np.array: The loaded and resized image.\n",
        "    \"\"\"\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize(target_size)\n",
        "    image = img_to_array(image)\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "oGf9X2yz-iaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://vis-www.cs.umass.edu/lfw/lfw.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME4M5xWgkU-_",
        "outputId": "df4035ed-4d6d-481f-b825-8227f0234c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-17 18:19:18--  http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
            "Resolving vis-www.cs.umass.edu (vis-www.cs.umass.edu)... 128.119.244.95\n",
            "Connecting to vis-www.cs.umass.edu (vis-www.cs.umass.edu)|128.119.244.95|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180566744 (172M) [application/x-gzip]\n",
            "Saving to: ‘lfw.tgz’\n",
            "\n",
            "lfw.tgz              97%[==================> ] 167.51M  --.-KB/s    eta 12s    "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: unzip the lfw.tgz file\n",
        "\n",
        "!tar -xzvf lfw.tgz\n"
      ],
      "metadata": {
        "id": "icefsQkjlEKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Triplet generator"
      ],
      "metadata": {
        "id": "Vw3oQVQY-mpe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xfrJOKNifzYT"
      },
      "outputs": [],
      "source": [
        "class TripletGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, main_dir, target_size=(160, 160), batch_size=32):\n",
        "        \"\"\"\n",
        "        Initialize the TripletGenerator.\n",
        "\n",
        "        Args:\n",
        "        main_dir (str): Path to the main directory containing class subdirectories.\n",
        "        target_size (tuple): Desired image size (width, height).\n",
        "        batch_size (int): Number of triplets per batch.\n",
        "        \"\"\"\n",
        "        self.main_dir = main_dir\n",
        "        self.target_size = target_size\n",
        "        self.batch_size = batch_size\n",
        "        self.class_dirs = [os.path.join(main_dir, d) for d in os.listdir(main_dir) if os.path.isdir(os.path.join(main_dir, d))]\n",
        "        self.class_images = {d: [os.path.join(d, img) for img in os.listdir(d) if img.endswith(('.png', '.jpg', '.jpeg'))] for d in self.class_dirs}\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.class_dirs) * self.batch_size / 3))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        anchors = []\n",
        "        positives = []\n",
        "        negatives = []\n",
        "\n",
        "        for _ in range(self.batch_size):\n",
        "            anchor_class = random.choice(list(self.class_images.keys()))\n",
        "            positive_class = anchor_class\n",
        "            negative_class = random.choice(list(self.class_images.keys()))\n",
        "\n",
        "            while anchor_class == negative_class:\n",
        "                negative_class = random.choice(list(self.class_images.keys()))\n",
        "\n",
        "            anchor_img = random.choice(self.class_images[anchor_class])\n",
        "            positive_img = random.choice(self.class_images[positive_class])\n",
        "            negative_img = random.choice(self.class_images[negative_class])\n",
        "\n",
        "            anchor_img = load_image(anchor_img, self.target_size)\n",
        "            positive_img = load_image(positive_img, self.target_size)\n",
        "            negative_img = load_image(negative_img, self.target_size)\n",
        "\n",
        "            anchors.append(anchor_img)\n",
        "            positives.append(positive_img)\n",
        "            negatives.append(negative_img)\n",
        "\n",
        "        return [np.array(anchors), np.array(positives), np.array(negatives)], np.ones(self.batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "whpaSOoYfzYT",
        "outputId": "32afb82f-748f-47b0-9308-ae1cb24df9e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_2\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, None, None, None) dtype=float32>]\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c0a5b365698e>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_2\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, None, None, None) dtype=float32>]\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "main_dir = \"lfw\"  # Replace with the actual path to your main directory\n",
        "target_size = (160, 160)\n",
        "batch_size = 32\n",
        "\n",
        "# Create the triplet generator\n",
        "train_generator = TripletGenerator(main_dir=main_dir, target_size=target_size, batch_size=batch_size)\n",
        "\n",
        "# Example model\n",
        "model = create_model()  # Assuming create_model() is defined as in the previous example\n",
        "model.compile(optimizer=Adam(1e-4), loss=TripletSemiHardLoss())\n",
        "\n",
        "\n",
        "initial_unfreeze_layers = 10\n",
        "step_unfreeze_layers = 5\n",
        "accuracy_threshold = 0.90\n",
        "patience = 3\n",
        "\n",
        "callbacks = [DynamicUnfreezeCallback(model, initial_unfreeze_layers, step_unfreeze_layers, accuracy_threshold, patience)]\n",
        "\n",
        "# model.fit(train_generator,\n",
        "#           epochs=50,\n",
        "#           steps_per_epoch=100,\n",
        "#           validation_data=val_generator,\n",
        "#           validation_steps=10,\n",
        "#           callbacks=callbacks)\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=50, steps_per_epoch=len(train_generator), callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New Code"
      ],
      "metadata": {
        "id": "KYW7FCIa-0I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "# from deepface.commons import package_utils, folder_utils\n",
        "# from deepface.models.FacialRecognition import FacialRecognition\n",
        "# from deepface.commons import logger as log\n",
        "\n",
        "# logger = log.get_singletonish_logger()\n",
        "\n",
        "# --------------------------------\n",
        "# dependency configuration\n",
        "\n",
        "# tf_version = package_utils.get_tf_major_version()\n",
        "\n",
        "# if tf_version == 1:\n",
        "#     from keras.models import Model\n",
        "#     from keras.layers import Activation\n",
        "#     from keras.layers import BatchNormalization\n",
        "#     from keras.layers import Concatenate\n",
        "#     from keras.layers import Conv2D\n",
        "#     from keras.layers import Dense\n",
        "#     from keras.layers import Dropout\n",
        "#     from keras.layers import GlobalAveragePooling2D\n",
        "#     from keras.layers import Input\n",
        "#     from keras.layers import Lambda\n",
        "#     from keras.layers import MaxPooling2D\n",
        "#     from keras.layers import add\n",
        "#     from keras import backend as K\n",
        "# else:\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import add\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def scaling(x, scale):\n",
        "    return x * scale\n",
        "\n",
        "\n",
        "def InceptionResNetV1(dimension: int = 128) -> Model:\n",
        "    \"\"\"\n",
        "    InceptionResNetV1 model heavily inspired from\n",
        "    github.com/davidsandberg/facenet/blob/master/src/models/inception_resnet_v1.py\n",
        "    As mentioned in Sandberg's repo's readme, pre-trained models are using Inception ResNet v1\n",
        "    Besides training process is documented at\n",
        "    sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/\n",
        "\n",
        "    Args:\n",
        "        dimension (int): number of dimensions in the embedding layer\n",
        "    Returns:\n",
        "        model (Model)\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = Input(shape=(160, 160, 3))\n",
        "    x = Conv2D(32, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Conv2d_1a_3x3\")(inputs)\n",
        "    x = BatchNormalization(\n",
        "        axis=3, momentum=0.995, epsilon=0.001, scale=False, name=\"Conv2d_1a_3x3_BatchNorm\"\n",
        "    )(x)\n",
        "    x = Activation(\"relu\", name=\"Conv2d_1a_3x3_Activation\")(x)\n",
        "    x = Conv2D(32, 3, strides=1, padding=\"valid\", use_bias=False, name=\"Conv2d_2a_3x3\")(x)\n",
        "    x = BatchNormalization(\n",
        "        axis=3, momentum=0.995, epsilon=0.001, scale=False, name=\"Conv2d_2a_3x3_BatchNorm\"\n",
        "    )(x)\n",
        "    x = Activation(\"relu\", name=\"Conv2d_2a_3x3_Activation\")(x)\n",
        "    x = Conv2D(64, 3, strides=1, padding=\"same\", use_bias=False, name=\"Conv2d_2b_3x3\")(x)\n",
        "    x = BatchNormalization(\n",
        "        axis=3, momentum=0.995, epsilon=0.001, scale=False, name=\"Conv2d_2b_3x3_BatchNorm\"\n",
        "    )(x)\n",
        "    x = Activation(\"relu\", name=\"Conv2d_2b_3x3_Activation\")(x)\n",
        "    x = MaxPooling2D(3, strides=2, name=\"MaxPool_3a_3x3\")(x)\n",
        "    x = Conv2D(80, 1, strides=1, padding=\"valid\", use_bias=False, name=\"Conv2d_3b_1x1\")(x)\n",
        "    x = BatchNormalization(\n",
        "        axis=3, momentum=0.995, epsilon=0.001, scale=False, name=\"Conv2d_3b_1x1_BatchNorm\"\n",
        "    )(x)\n",
        "    x = Activation(\"relu\", name=\"Conv2d_3b_1x1_Activation\")(x)\n",
        "    x = Conv2D(192, 3, strides=1, padding=\"valid\", use_bias=False, name=\"Conv2d_4a_3x3\")(x)\n",
        "    x = BatchNormalization(\n",
        "        axis=3, momentum=0.995, epsilon=0.001, scale=False, name=\"Conv2d_4a_3x3_BatchNorm\"\n",
        "    )(x)\n",
        "    x = Activation(\"relu\", name=\"Conv2d_4a_3x3_Activation\")(x)\n",
        "    x = Conv2D(256, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Conv2d_4b_3x3\")(x)\n",
        "    x = BatchNormalization(\n",
        "        axis=3, momentum=0.995, epsilon=0.001, scale=False, name=\"Conv2d_4b_3x3_BatchNorm\"\n",
        "    )(x)\n",
        "    x = Activation(\"relu\", name=\"Conv2d_4b_3x3_Activation\")(x)\n",
        "\n",
        "    # 5x Block35 (Inception-ResNet-A block):\n",
        "    branch_0 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_1_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_1_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block35_1_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_1_Branch_1_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_1_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block35_1_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_1_Branch_1_Conv2d_0b_3x3\"\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_1_Branch_1_Conv2d_0b_3x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block35_1_Branch_1_Conv2d_0b_3x3_Activation\")(branch_1)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_1_Branch_2_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_1_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_1_Branch_2_Conv2d_0a_1x1_Activation\")(branch_2)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_1_Branch_2_Conv2d_0b_3x3\"\n",
        "    )(branch_2)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_1_Branch_2_Conv2d_0b_3x3_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_1_Branch_2_Conv2d_0b_3x3_Activation\")(branch_2)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_1_Branch_2_Conv2d_0c_3x3\"\n",
        "    )(branch_2)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_1_Branch_2_Conv2d_0c_3x3_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_1_Branch_2_Conv2d_0c_3x3_Activation\")(branch_2)\n",
        "    branches = [branch_0, branch_1, branch_2]\n",
        "    mixed = Concatenate(axis=3, name=\"Block35_1_Concatenate\")(branches)\n",
        "    up = Conv2D(256, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block35_1_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.17})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block35_1_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_2_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_2_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block35_2_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_2_Branch_1_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_2_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block35_2_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_2_Branch_1_Conv2d_0b_3x3\"\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_2_Branch_1_Conv2d_0b_3x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block35_2_Branch_1_Conv2d_0b_3x3_Activation\")(branch_1)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_2_Branch_2_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_2_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_2_Branch_2_Conv2d_0a_1x1_Activation\")(branch_2)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_2_Branch_2_Conv2d_0b_3x3\"\n",
        "    )(branch_2)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_2_Branch_2_Conv2d_0b_3x3_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_2_Branch_2_Conv2d_0b_3x3_Activation\")(branch_2)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_2_Branch_2_Conv2d_0c_3x3\"\n",
        "    )(branch_2)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_2_Branch_2_Conv2d_0c_3x3_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_2_Branch_2_Conv2d_0c_3x3_Activation\")(branch_2)\n",
        "    branches = [branch_0, branch_1, branch_2]\n",
        "    mixed = Concatenate(axis=3, name=\"Block35_2_Concatenate\")(branches)\n",
        "    up = Conv2D(256, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block35_2_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.17})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block35_2_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_3_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_3_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block35_3_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_3_Branch_1_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_3_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block35_3_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_3_Branch_1_Conv2d_0b_3x3\"\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_3_Branch_1_Conv2d_0b_3x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block35_3_Branch_1_Conv2d_0b_3x3_Activation\")(branch_1)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_3_Branch_2_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_3_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_3_Branch_2_Conv2d_0a_1x1_Activation\")(branch_2)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_3_Branch_2_Conv2d_0b_3x3\"\n",
        "    )(branch_2)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_3_Branch_2_Conv2d_0b_3x3_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_3_Branch_2_Conv2d_0b_3x3_Activation\")(branch_2)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_3_Branch_2_Conv2d_0c_3x3\"\n",
        "    )(branch_2)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_3_Branch_2_Conv2d_0c_3x3_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_3_Branch_2_Conv2d_0c_3x3_Activation\")(branch_2)\n",
        "    branches = [branch_0, branch_1, branch_2]\n",
        "    mixed = Concatenate(axis=3, name=\"Block35_3_Concatenate\")(branches)\n",
        "    up = Conv2D(256, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block35_3_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.17})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block35_3_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_4_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_4_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block35_4_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_4_Branch_1_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_4_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block35_4_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_4_Branch_1_Conv2d_0b_3x3\"\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_4_Branch_1_Conv2d_0b_3x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block35_4_Branch_1_Conv2d_0b_3x3_Activation\")(branch_1)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_4_Branch_2_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_4_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_4_Branch_2_Conv2d_0a_1x1_Activation\")(branch_2)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_4_Branch_2_Conv2d_0b_3x3\"\n",
        "    )(branch_2)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_4_Branch_2_Conv2d_0b_3x3_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_4_Branch_2_Conv2d_0b_3x3_Activation\")(branch_2)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_4_Branch_2_Conv2d_0c_3x3\"\n",
        "    )(branch_2)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_4_Branch_2_Conv2d_0c_3x3_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_4_Branch_2_Conv2d_0c_3x3_Activation\")(branch_2)\n",
        "    branches = [branch_0, branch_1, branch_2]\n",
        "    mixed = Concatenate(axis=3, name=\"Block35_4_Concatenate\")(branches)\n",
        "    up = Conv2D(256, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block35_4_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.17})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block35_4_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_5_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_5_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block35_5_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_5_Branch_1_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_5_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block35_5_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_5_Branch_1_Conv2d_0b_3x3\"\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_5_Branch_1_Conv2d_0b_3x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block35_5_Branch_1_Conv2d_0b_3x3_Activation\")(branch_1)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block35_5_Branch_2_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_5_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_5_Branch_2_Conv2d_0a_1x1_Activation\")(branch_2)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_5_Branch_2_Conv2d_0b_3x3\"\n",
        "    )(branch_2)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_5_Branch_2_Conv2d_0b_3x3_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_5_Branch_2_Conv2d_0b_3x3_Activation\")(branch_2)\n",
        "    branch_2 = Conv2D(\n",
        "        32, 3, strides=1, padding=\"same\", use_bias=False, name=\"Block35_5_Branch_2_Conv2d_0c_3x3\"\n",
        "    )(branch_2)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block35_5_Branch_2_Conv2d_0c_3x3_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Block35_5_Branch_2_Conv2d_0c_3x3_Activation\")(branch_2)\n",
        "    branches = [branch_0, branch_1, branch_2]\n",
        "    mixed = Concatenate(axis=3, name=\"Block35_5_Concatenate\")(branches)\n",
        "    up = Conv2D(256, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block35_5_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.17})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block35_5_Activation\")(x)\n",
        "\n",
        "    # Mixed 6a (Reduction-A block):\n",
        "    branch_0 = Conv2D(\n",
        "        384, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Mixed_6a_Branch_0_Conv2d_1a_3x3\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Mixed_6a_Branch_0_Conv2d_1a_3x3_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Mixed_6a_Branch_0_Conv2d_1a_3x3_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Mixed_6a_Branch_1_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Mixed_6a_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Mixed_6a_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192, 3, strides=1, padding=\"same\", use_bias=False, name=\"Mixed_6a_Branch_1_Conv2d_0b_3x3\"\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Mixed_6a_Branch_1_Conv2d_0b_3x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Mixed_6a_Branch_1_Conv2d_0b_3x3_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        256, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Mixed_6a_Branch_1_Conv2d_1a_3x3\"\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Mixed_6a_Branch_1_Conv2d_1a_3x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Mixed_6a_Branch_1_Conv2d_1a_3x3_Activation\")(branch_1)\n",
        "    branch_pool = MaxPooling2D(\n",
        "        3, strides=2, padding=\"valid\", name=\"Mixed_6a_Branch_2_MaxPool_1a_3x3\"\n",
        "    )(x)\n",
        "    branches = [branch_0, branch_1, branch_pool]\n",
        "    x = Concatenate(axis=3, name=\"Mixed_6a\")(branches)\n",
        "\n",
        "    # 10x Block17 (Inception-ResNet-B block):\n",
        "    branch_0 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_1_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_1_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block17_1_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_1_Branch_1_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_1_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_1_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [1, 7],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_1_Branch_1_Conv2d_0b_1x7\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_1_Branch_1_Conv2d_0b_1x7_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_1_Branch_1_Conv2d_0b_1x7_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [7, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_1_Branch_1_Conv2d_0c_7x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_1_Branch_1_Conv2d_0c_7x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_1_Branch_1_Conv2d_0c_7x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block17_1_Concatenate\")(branches)\n",
        "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_1_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block17_1_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_2_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_2_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block17_2_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_2_Branch_2_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_2_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_2_Branch_2_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [1, 7],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_2_Branch_2_Conv2d_0b_1x7\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_2_Branch_2_Conv2d_0b_1x7_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_2_Branch_2_Conv2d_0b_1x7_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [7, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_2_Branch_2_Conv2d_0c_7x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_2_Branch_2_Conv2d_0c_7x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_2_Branch_2_Conv2d_0c_7x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block17_2_Concatenate\")(branches)\n",
        "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_2_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block17_2_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_3_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_3_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block17_3_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_3_Branch_3_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_3_Branch_3_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_3_Branch_3_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [1, 7],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_3_Branch_3_Conv2d_0b_1x7\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_3_Branch_3_Conv2d_0b_1x7_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_3_Branch_3_Conv2d_0b_1x7_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [7, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_3_Branch_3_Conv2d_0c_7x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_3_Branch_3_Conv2d_0c_7x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_3_Branch_3_Conv2d_0c_7x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block17_3_Concatenate\")(branches)\n",
        "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_3_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block17_3_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_4_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_4_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block17_4_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_4_Branch_4_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_4_Branch_4_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_4_Branch_4_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [1, 7],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_4_Branch_4_Conv2d_0b_1x7\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_4_Branch_4_Conv2d_0b_1x7_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_4_Branch_4_Conv2d_0b_1x7_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [7, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_4_Branch_4_Conv2d_0c_7x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_4_Branch_4_Conv2d_0c_7x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_4_Branch_4_Conv2d_0c_7x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block17_4_Concatenate\")(branches)\n",
        "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_4_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block17_4_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_5_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_5_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block17_5_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_5_Branch_5_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_5_Branch_5_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_5_Branch_5_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [1, 7],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_5_Branch_5_Conv2d_0b_1x7\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_5_Branch_5_Conv2d_0b_1x7_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_5_Branch_5_Conv2d_0b_1x7_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [7, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_5_Branch_5_Conv2d_0c_7x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_5_Branch_5_Conv2d_0c_7x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_5_Branch_5_Conv2d_0c_7x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block17_5_Concatenate\")(branches)\n",
        "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_5_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block17_5_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_6_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_6_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block17_6_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_6_Branch_6_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_6_Branch_6_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_6_Branch_6_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [1, 7],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_6_Branch_6_Conv2d_0b_1x7\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_6_Branch_6_Conv2d_0b_1x7_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_6_Branch_6_Conv2d_0b_1x7_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [7, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_6_Branch_6_Conv2d_0c_7x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_6_Branch_6_Conv2d_0c_7x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_6_Branch_6_Conv2d_0c_7x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block17_6_Concatenate\")(branches)\n",
        "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_6_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block17_6_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_7_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_7_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block17_7_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_7_Branch_7_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_7_Branch_7_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_7_Branch_7_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [1, 7],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_7_Branch_7_Conv2d_0b_1x7\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_7_Branch_7_Conv2d_0b_1x7_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_7_Branch_7_Conv2d_0b_1x7_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [7, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_7_Branch_7_Conv2d_0c_7x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_7_Branch_7_Conv2d_0c_7x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_7_Branch_7_Conv2d_0c_7x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block17_7_Concatenate\")(branches)\n",
        "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_7_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block17_7_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_8_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_8_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block17_8_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_8_Branch_8_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_8_Branch_8_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_8_Branch_8_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [1, 7],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_8_Branch_8_Conv2d_0b_1x7\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_8_Branch_8_Conv2d_0b_1x7_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_8_Branch_8_Conv2d_0b_1x7_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [7, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_8_Branch_8_Conv2d_0c_7x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_8_Branch_8_Conv2d_0c_7x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_8_Branch_8_Conv2d_0c_7x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block17_8_Concatenate\")(branches)\n",
        "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_8_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block17_8_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_9_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_9_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block17_9_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_9_Branch_9_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_9_Branch_9_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_9_Branch_9_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [1, 7],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_9_Branch_9_Conv2d_0b_1x7\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_9_Branch_9_Conv2d_0b_1x7_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_9_Branch_9_Conv2d_0b_1x7_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [7, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_9_Branch_9_Conv2d_0c_7x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_9_Branch_9_Conv2d_0c_7x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_9_Branch_9_Conv2d_0c_7x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block17_9_Concatenate\")(branches)\n",
        "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_9_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block17_9_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_10_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_10_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block17_10_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        128, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block17_10_Branch_10_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_10_Branch_10_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_10_Branch_10_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [1, 7],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_10_Branch_10_Conv2d_0b_1x7\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_10_Branch_10_Conv2d_0b_1x7_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_10_Branch_10_Conv2d_0b_1x7_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        128,\n",
        "        [7, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block17_10_Branch_10_Conv2d_0c_7x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block17_10_Branch_10_Conv2d_0c_7x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block17_10_Branch_10_Conv2d_0c_7x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block17_10_Concatenate\")(branches)\n",
        "    up = Conv2D(896, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block17_10_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.1})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block17_10_Activation\")(x)\n",
        "\n",
        "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
        "    branch_0 = Conv2D(\n",
        "        256, 1, strides=1, padding=\"same\", use_bias=False, name=\"Mixed_7a_Branch_0_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Mixed_7a_Branch_0_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Mixed_7a_Branch_0_Conv2d_0a_1x1_Activation\")(branch_0)\n",
        "    branch_0 = Conv2D(\n",
        "        384, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Mixed_7a_Branch_0_Conv2d_1a_3x3\"\n",
        "    )(branch_0)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Mixed_7a_Branch_0_Conv2d_1a_3x3_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Mixed_7a_Branch_0_Conv2d_1a_3x3_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        256, 1, strides=1, padding=\"same\", use_bias=False, name=\"Mixed_7a_Branch_1_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Mixed_7a_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Mixed_7a_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        256, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Mixed_7a_Branch_1_Conv2d_1a_3x3\"\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Mixed_7a_Branch_1_Conv2d_1a_3x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Mixed_7a_Branch_1_Conv2d_1a_3x3_Activation\")(branch_1)\n",
        "    branch_2 = Conv2D(\n",
        "        256, 1, strides=1, padding=\"same\", use_bias=False, name=\"Mixed_7a_Branch_2_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Mixed_7a_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Mixed_7a_Branch_2_Conv2d_0a_1x1_Activation\")(branch_2)\n",
        "    branch_2 = Conv2D(\n",
        "        256, 3, strides=1, padding=\"same\", use_bias=False, name=\"Mixed_7a_Branch_2_Conv2d_0b_3x3\"\n",
        "    )(branch_2)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Mixed_7a_Branch_2_Conv2d_0b_3x3_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Mixed_7a_Branch_2_Conv2d_0b_3x3_Activation\")(branch_2)\n",
        "    branch_2 = Conv2D(\n",
        "        256, 3, strides=2, padding=\"valid\", use_bias=False, name=\"Mixed_7a_Branch_2_Conv2d_1a_3x3\"\n",
        "    )(branch_2)\n",
        "    branch_2 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Mixed_7a_Branch_2_Conv2d_1a_3x3_BatchNorm\",\n",
        "    )(branch_2)\n",
        "    branch_2 = Activation(\"relu\", name=\"Mixed_7a_Branch_2_Conv2d_1a_3x3_Activation\")(branch_2)\n",
        "    branch_pool = MaxPooling2D(\n",
        "        3, strides=2, padding=\"valid\", name=\"Mixed_7a_Branch_3_MaxPool_1a_3x3\"\n",
        "    )(x)\n",
        "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
        "    x = Concatenate(axis=3, name=\"Mixed_7a\")(branches)\n",
        "\n",
        "    # 5x Block8 (Inception-ResNet-C block):\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_1_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_1_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block8_1_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_1_Branch_1_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_1_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_1_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192,\n",
        "        [1, 3],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block8_1_Branch_1_Conv2d_0b_1x3\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_1_Branch_1_Conv2d_0b_1x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_1_Branch_1_Conv2d_0b_1x3_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192,\n",
        "        [3, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block8_1_Branch_1_Conv2d_0c_3x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_1_Branch_1_Conv2d_0c_3x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_1_Branch_1_Conv2d_0c_3x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block8_1_Concatenate\")(branches)\n",
        "    up = Conv2D(1792, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block8_1_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.2})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block8_1_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_2_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_2_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block8_2_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_2_Branch_2_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_2_Branch_2_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_2_Branch_2_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192,\n",
        "        [1, 3],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block8_2_Branch_2_Conv2d_0b_1x3\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_2_Branch_2_Conv2d_0b_1x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_2_Branch_2_Conv2d_0b_1x3_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192,\n",
        "        [3, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block8_2_Branch_2_Conv2d_0c_3x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_2_Branch_2_Conv2d_0c_3x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_2_Branch_2_Conv2d_0c_3x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block8_2_Concatenate\")(branches)\n",
        "    up = Conv2D(1792, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block8_2_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.2})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block8_2_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_3_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_3_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block8_3_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_3_Branch_3_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_3_Branch_3_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_3_Branch_3_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192,\n",
        "        [1, 3],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block8_3_Branch_3_Conv2d_0b_1x3\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_3_Branch_3_Conv2d_0b_1x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_3_Branch_3_Conv2d_0b_1x3_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192,\n",
        "        [3, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block8_3_Branch_3_Conv2d_0c_3x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_3_Branch_3_Conv2d_0c_3x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_3_Branch_3_Conv2d_0c_3x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block8_3_Concatenate\")(branches)\n",
        "    up = Conv2D(1792, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block8_3_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.2})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block8_3_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_4_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_4_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block8_4_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_4_Branch_4_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_4_Branch_4_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_4_Branch_4_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192,\n",
        "        [1, 3],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block8_4_Branch_4_Conv2d_0b_1x3\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_4_Branch_4_Conv2d_0b_1x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_4_Branch_4_Conv2d_0b_1x3_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192,\n",
        "        [3, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block8_4_Branch_4_Conv2d_0c_3x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_4_Branch_4_Conv2d_0c_3x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_4_Branch_4_Conv2d_0c_3x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block8_4_Concatenate\")(branches)\n",
        "    up = Conv2D(1792, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block8_4_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.2})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block8_4_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_5_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_5_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block8_5_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_5_Branch_5_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_5_Branch_5_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_5_Branch_5_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192,\n",
        "        [1, 3],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block8_5_Branch_5_Conv2d_0b_1x3\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_5_Branch_5_Conv2d_0b_1x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_5_Branch_5_Conv2d_0b_1x3_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192,\n",
        "        [3, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block8_5_Branch_5_Conv2d_0c_3x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_5_Branch_5_Conv2d_0c_3x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_5_Branch_5_Conv2d_0c_3x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block8_5_Concatenate\")(branches)\n",
        "    up = Conv2D(1792, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block8_5_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 0.2})(up)\n",
        "    x = add([x, up])\n",
        "    x = Activation(\"relu\", name=\"Block8_5_Activation\")(x)\n",
        "\n",
        "    branch_0 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_6_Branch_0_Conv2d_1x1\"\n",
        "    )(x)\n",
        "    branch_0 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_6_Branch_0_Conv2d_1x1_BatchNorm\",\n",
        "    )(branch_0)\n",
        "    branch_0 = Activation(\"relu\", name=\"Block8_6_Branch_0_Conv2d_1x1_Activation\")(branch_0)\n",
        "    branch_1 = Conv2D(\n",
        "        192, 1, strides=1, padding=\"same\", use_bias=False, name=\"Block8_6_Branch_1_Conv2d_0a_1x1\"\n",
        "    )(x)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_6_Branch_1_Conv2d_0a_1x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_6_Branch_1_Conv2d_0a_1x1_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192,\n",
        "        [1, 3],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block8_6_Branch_1_Conv2d_0b_1x3\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_6_Branch_1_Conv2d_0b_1x3_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_6_Branch_1_Conv2d_0b_1x3_Activation\")(branch_1)\n",
        "    branch_1 = Conv2D(\n",
        "        192,\n",
        "        [3, 1],\n",
        "        strides=1,\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"Block8_6_Branch_1_Conv2d_0c_3x1\",\n",
        "    )(branch_1)\n",
        "    branch_1 = BatchNormalization(\n",
        "        axis=3,\n",
        "        momentum=0.995,\n",
        "        epsilon=0.001,\n",
        "        scale=False,\n",
        "        name=\"Block8_6_Branch_1_Conv2d_0c_3x1_BatchNorm\",\n",
        "    )(branch_1)\n",
        "    branch_1 = Activation(\"relu\", name=\"Block8_6_Branch_1_Conv2d_0c_3x1_Activation\")(branch_1)\n",
        "    branches = [branch_0, branch_1]\n",
        "    mixed = Concatenate(axis=3, name=\"Block8_6_Concatenate\")(branches)\n",
        "    up = Conv2D(1792, 1, strides=1, padding=\"same\", use_bias=True, name=\"Block8_6_Conv2d_1x1\")(\n",
        "        mixed\n",
        "    )\n",
        "    up = Lambda(scaling, output_shape=K.int_shape(up)[1:], arguments={\"scale\": 1})(up)\n",
        "    x = add([x, up])\n",
        "\n",
        "    # Classification block\n",
        "    x = GlobalAveragePooling2D(name=\"AvgPool\")(x)\n",
        "    x = Dropout(1.0 - 0.8, name=\"Dropout\")(x)\n",
        "    # Bottleneck\n",
        "    x = Dense(dimension, use_bias=False, name=\"Bottleneck\")(x)\n",
        "    x = BatchNormalization(momentum=0.995, epsilon=0.001, scale=False, name=\"Bottleneck_BatchNorm\")(\n",
        "        x\n",
        "    )\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs, x, name=\"inception_resnet_v1\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_facenet128d_model(\n",
        "    url=\"https://github.com/serengil/deepface_models/releases/download/v1.0/facenet_weights.h5\",\n",
        ") -> Model:\n",
        "    \"\"\"\n",
        "    Construct FaceNet-128d model, download weights and then load weights\n",
        "    Args:\n",
        "        dimension (int): construct FaceNet-128d or FaceNet-512d models\n",
        "    Returns:\n",
        "        model (Model)\n",
        "    \"\"\"\n",
        "    model = InceptionResNetV1()\n",
        "\n",
        "    # -----------------------------------\n",
        "\n",
        "    home = folder_utils.get_deepface_home()\n",
        "\n",
        "    if os.path.isfile(home + \"/.deepface/weights/facenet_weights.h5\") != True:\n",
        "        logger.info(\"facenet_weights.h5 will be downloaded...\")\n",
        "\n",
        "        output = home + \"/.deepface/weights/facenet_weights.h5\"\n",
        "        gdown.download(url, output, quiet=False)\n",
        "\n",
        "    # -----------------------------------\n",
        "\n",
        "    model.load_weights(home + \"/.deepface/weights/facenet_weights.h5\")\n",
        "\n",
        "    # -----------------------------------\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_facenet512d_model(\n",
        "    url=\"https://github.com/serengil/deepface_models/releases/download/v1.0/facenet512_weights.h5\",\n",
        ") -> Model:\n",
        "    \"\"\"\n",
        "    Construct FaceNet-512d model, download its weights and load\n",
        "    Returns:\n",
        "        model (Model)\n",
        "    \"\"\"\n",
        "\n",
        "    model = InceptionResNetV1(dimension=512)\n",
        "\n",
        "    # -------------------------\n",
        "\n",
        "    home = folder_utils.get_deepface_home()\n",
        "\n",
        "    if os.path.isfile(home + \"/.deepface/weights/facenet512_weights.h5\") != True:\n",
        "        logger.info(\"facenet512_weights.h5 will be downloaded...\")\n",
        "\n",
        "        output = home + \"/.deepface/weights/facenet512_weights.h5\"\n",
        "        gdown.download(url, output, quiet=False)\n",
        "\n",
        "    # -------------------------\n",
        "\n",
        "    model.load_weights(home + \"/.deepface/weights/facenet512_weights.h5\")\n",
        "\n",
        "    # -------------------------\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "cDyfzqiN_0mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.applications import InceptionResNetV1\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from PIL import Image\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def load_facenet128d_model(url=\"https://github.com/serengil/deepface_models/releases/download/v1.0/facenet_weights.h5\") -> Model:\n",
        "    model = InceptionResNetV1()\n",
        "    home = os.path.expanduser(\"~\")\n",
        "    weight_path = os.path.join(home, \".deepface\", \"weights\", \"facenet_weights.h5\")\n",
        "    if not os.path.isfile(weight_path):\n",
        "        os.makedirs(os.path.dirname(weight_path), exist_ok=True)\n",
        "        gdown.download(url, weight_path, quiet=False)\n",
        "    model.load_weights(weight_path)\n",
        "    return model\n",
        "\n",
        "class TripletGenerator(Sequence):\n",
        "    def __init__(self, directory, batch_size=32, target_size=(160, 160)):\n",
        "        self.directory = directory\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.classes = os.listdir(directory)\n",
        "        self.class_indices = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.file_paths = {cls: [os.path.join(directory, cls, fname) for fname in os.listdir(os.path.join(directory, cls))] for cls in self.classes}\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.classes) * self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_triplets = []\n",
        "        for _ in range(self.batch_size):\n",
        "            anchor_class = random.choice(self.classes)\n",
        "            negative_class = random.choice([cls for cls in self.classes if cls != anchor_class])\n",
        "            anchor_img = random.choice(self.file_paths[anchor_class])\n",
        "            positive_img = random.choice(self.file_paths[anchor_class])\n",
        "            negative_img = random.choice(self.file_paths[negative_class])\n",
        "            anchor = self.load_image(anchor_img)\n",
        "            positive = self.load_image(positive_img)\n",
        "            negative = self.load_image(negative_img)\n",
        "            batch_triplets.append((anchor, positive, negative))\n",
        "        batch_triplets = np.array(batch_triplets)\n",
        "        return [batch_triplets[:, 0], batch_triplets[:, 1], batch_triplets[:, 2]], np.zeros((self.batch_size, 1))\n",
        "\n",
        "    def load_image(self, path):\n",
        "        img = Image.open(path).resize(self.target_size)\n",
        "        img = np.array(img) / 255.0\n",
        "        return img\n",
        "\n",
        "class DynamicUnfreeze(Callback):\n",
        "    def __init__(self, model, validation_data, accuracy_threshold, layers_to_unfreeze):\n",
        "        super(DynamicUnfreeze, self).__init__()\n",
        "        self.model = model\n",
        "        self.validation_data = validation_data\n",
        "        self.accuracy_threshold = accuracy_threshold\n",
        "        self.layers_to_unfreeze = layers_to_unfreeze\n",
        "        self.patience = 3\n",
        "        self.wait = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_accuracy = logs.get('val_accuracy')\n",
        "        if val_accuracy > self.accuracy_threshold:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.wait = 0\n",
        "                self.unfreeze_layers()\n",
        "\n",
        "    def unfreeze_layers(self):\n",
        "        layers = self.model.layers\n",
        "        unfrozen_layers = sum([layer.trainable for layer in layers])\n",
        "        if unfrozen_layers < len(layers):\n",
        "            for layer in layers[-self.layers_to_unfreeze:]:\n",
        "                layer.trainable = True\n",
        "            print(f\"Unfroze {self.layers_to_unfreeze} more layers. Total unfrozen layers: {unfrozen_layers + self.layers_to_unfreeze}\")\n",
        "\n",
        "def triplet_loss(y_true, y_pred, alpha=0.2):\n",
        "    anchor, positive, negative = y_pred[:, 0], y_pred[:, 1], y_pred[:, 2]\n",
        "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
        "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
        "    loss = tf.maximum(pos_dist - neg_dist + alpha, 0.0)\n",
        "    return loss\n",
        "\n",
        "model = load_facenet128d_model()\n",
        "for layer in model.layers[:-10]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=triplet_loss, metrics=['accuracy'])\n",
        "\n",
        "train_generator = TripletGenerator(directory=\"lfw\", batch_size=32)\n",
        "val_generator = TripletGenerator(directory=\"lfw\", batch_size=32)\n",
        "dynamic_unfreeze = DynamicUnfreeze(model=model, validation_data=val_generator, accuracy_threshold=0.90, layers_to_unfreeze=5)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=100,\n",
        "    callbacks=[dynamic_unfreeze]\n",
        ")\n"
      ],
      "metadata": {
        "id": "3P4anBxo-zDD",
        "outputId": "60e88c3f-77b7-434f-df2b-f4a0a024181f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facenet_weights.h5\n",
            "To: /root/.deepface/weights/facenet_weights.h5\n",
            "100%|██████████| 92.2M/92.2M [00:00<00:00, 236MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"inception_resnet_v1\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, None, None, None) dtype=float32>]\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-4258e5d4f3a1>\u001b[0m in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mdynamic_unfreeze\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDynamicUnfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_to_unfreeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"inception_resnet_v1\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None, None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, None, None, None) dtype=float32>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 2.1"
      ],
      "metadata": {
        "id": "tKwlBrPfBONT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_model():\n",
        "    model = load_facenet128d_model()\n",
        "    embedding = model.output\n",
        "    embedding_model = Model(inputs=model.input, outputs=embedding)\n",
        "    return embedding_model\n",
        "\n",
        "embedding_model = create_embedding_model()\n"
      ],
      "metadata": {
        "id": "EqYSKYlsBQGX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletGenerator(Sequence):\n",
        "    def __init__(self, directory, batch_size=32, target_size=(160, 160)):\n",
        "        self.directory = directory\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.classes = os.listdir(directory)\n",
        "        self.class_indices = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.file_paths = {cls: [os.path.join(directory, cls, fname) for fname in os.listdir(os.path.join(directory, cls))] for cls in self.classes}\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.classes) * self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_triplets = []\n",
        "        for _ in range(self.batch_size):\n",
        "            anchor_class = random.choice(self.classes)\n",
        "            negative_class = random.choice([cls for cls in self.classes if cls != anchor_class])\n",
        "            anchor_img = random.choice(self.file_paths[anchor_class])\n",
        "            positive_img = random.choice(self.file_paths[anchor_class])\n",
        "            negative_img = random.choice(self.file_paths[negative_class])\n",
        "            anchor = self.load_image(anchor_img)\n",
        "            positive = self.load_image(positive_img)\n",
        "            negative = self.load_image(negative_img)\n",
        "            batch_triplets.append((anchor, positive, negative))\n",
        "        batch_triplets = np.array(batch_triplets)\n",
        "        return batch_triplets[:, 0], batch_triplets[:, 1], batch_triplets[:, 2]\n",
        "\n",
        "    def load_image(self, path):\n",
        "        img = Image.open(path).resize(self.target_size)\n",
        "        img = np.array(img) / 255.0\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "HzzW3L3JBwfM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class DynamicUnfreeze(Callback):\n",
        "    def __init__(self, model, accuracy_threshold, layers_to_unfreeze):\n",
        "        super(DynamicUnfreeze, self).__init__()\n",
        "        self.model = model\n",
        "        self.accuracy_threshold = accuracy_threshold\n",
        "        self.layers_to_unfreeze = layers_to_unfreeze\n",
        "        self.patience = 3\n",
        "        self.wait = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_accuracy = logs.get('val_accuracy')\n",
        "        if val_accuracy > self.accuracy_threshold:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.wait = 0\n",
        "                self.unfreeze_layers()\n",
        "\n",
        "    def unfreeze_layers(self):\n",
        "        layers = self.model.layers\n",
        "        unfrozen_layers = sum([layer.trainable for layer in layers])\n",
        "        if unfrozen_layers < len(layers):\n",
        "            for layer in layers[-self.layers_to_unfreeze:]:\n",
        "                layer.trainable = True\n",
        "            print(f\"Unfroze {self.layers_to_unfreeze} more layers. Total unfrozen layers: {unfrozen_layers + self.layers_to_unfreeze}\")\n",
        "\n",
        "def triplet_loss(anchor, positive, negative, alpha=0.2):\n",
        "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
        "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
        "    return tf.maximum(pos_dist - neg_dist + alpha, 0.0)\n",
        "\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "\n",
        "@tf.function\n",
        "def train_step(anchor, positive, negative, model):\n",
        "    with tf.GradientTape() as tape:\n",
        "        anchor_emb = model(anchor, training=True)\n",
        "        positive_emb = model(positive, training=True)\n",
        "        negative_emb = model(negative, training=True)\n",
        "        loss = triplet_loss(anchor_emb, positive_emb, negative_emb)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "def custom_training_loop(model, train_dataset, val_dataset, epochs, callback):\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        print(f'Starting epoch {epoch+1}/{epochs}')\n",
        "        for anchor, positive, negative in tqdm(train_dataset):\n",
        "            loss = train_step(anchor, positive, negative, model)\n",
        "\n",
        "        # Validation\n",
        "        val_accuracies = []\n",
        "        for anchor, positive, negative in tqdm(val_dataset):\n",
        "            anchor_emb = model(anchor, training=False)\n",
        "            positive_emb = model(positive, training=False)\n",
        "            negative_emb = model(negative, training=False)\n",
        "            val_accuracies.append(tf.reduce_mean(tf.cast(tf.reduce_sum(tf.square(anchor_emb - positive_emb), axis=-1) <\n",
        "                                                         tf.reduce_sum(tf.square(anchor_emb - negative_emb), axis=-1), tf.float32)))\n",
        "        val_accuracy = tf.reduce_mean(val_accuracies)\n",
        "        print(f'Epoch {epoch+1} validation accuracy: {val_accuracy.numpy()}')\n",
        "        logs = {'val_accuracy': val_accuracy}\n",
        "        callback.on_epoch_end(epoch, logs)\n",
        "\n",
        "train_dataset = TripletGenerator(directory=\"lfw\", batch_size=32)\n",
        "val_dataset = TripletGenerator(directory=\"lfw\", batch_size=32)\n",
        "callback = DynamicUnfreeze(model=embedding_model, accuracy_threshold=0.90, layers_to_unfreeze=5)\n",
        "\n",
        "custom_training_loop(model=embedding_model, train_dataset=train_dataset, val_dataset=val_dataset, epochs=100, callback=callback)\n"
      ],
      "metadata": {
        "id": "lVY2t4ljBSEH",
        "outputId": "e301ba01-4d6d-4811-d5fc-7a09fbb82dcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "5795f294857943348d4f352a7ea17a28",
            "6eb53574ed79461b944ff4751e7597a3",
            "73e8cb6a7774407c8464912a7374d021",
            "73cca73299d241a3aa436d36b4d5b208",
            "b7b404e1ad0c4f62bf2d9ae63640abbb",
            "f19eaad38eac42baae6aae340cb40e80",
            "a3a8690f41b743feaa02d895796dca42",
            "0a6abd7096414256baa9e7cd8b84430d",
            "a7ba4218461645f2b4142e1575e67da9",
            "1625f16e79a949f1beb2735e12b1d042",
            "e3a0573538164ff7a7ecb5f0aae29c17",
            "ac2c4884ca6c4800b7def20ce4427e50",
            "98ea69cf41654cb0adc711879d6c2b14",
            "2d4182f1326b41bfa82afc675c0f4be3",
            "fbad2574a7b045e4b0ce57b402166daa",
            "f3573b97b0ae4bf6a881f5fc332ce3db",
            "0a48cdd11bc640a395aa0a6f9bed9b07",
            "d57b338e017c4547b92cd55392d8c281",
            "13055fe7d6784554966b4b23e2ec38cd",
            "9db5738256da4e88aa162ffa2f7cef2b",
            "9ae3d93eb6bc47caa77b84b6690130a0",
            "7abf016947f749e0b62d141f6188deda"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5795f294857943348d4f352a7ea17a28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1/100\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/183968 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac2c4884ca6c4800b7def20ce4427e50"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# Ensure TensorFlow Similarity is installed\n",
        "try:\n",
        "    import tensorflow_similarity as tfsim\n",
        "except ModuleNotFoundError:\n",
        "    !pip install tensorflow_similarity\n",
        "    import tensorflow_similarity as tfsim\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow_similarity.models import SimilarityModel\n",
        "from tensorflow_similarity.layers import MetricEmbedding\n",
        "from tensorflow_similarity.losses import TripletLoss\n",
        "from tensorflow_similarity.samplers import select_examples\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "import tensorflow_similarity as tfsim\n",
        "\n",
        "\n",
        "class TripletGenerator(Sequence):\n",
        "    def __init__(self, directory, batch_size=32, target_size=(160, 160)):\n",
        "        self.directory = directory\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.classes = os.listdir(directory)\n",
        "        self.class_indices = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.file_paths = {cls: [os.path.join(directory, cls, fname) for fname in os.listdir(os.path.join(directory, cls))] for cls in self.classes}\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.classes) * self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_triplets = []\n",
        "        for _ in range(self.batch_size):\n",
        "            anchor_class = random.choice(self.classes)\n",
        "            negative_class = random.choice([cls for cls in self.classes if cls != anchor_class])\n",
        "            anchor_img = random.choice(self.file_paths[anchor_class])\n",
        "            positive_img = random.choice(self.file_paths[anchor_class])\n",
        "            negative_img = random.choice(self.file_paths[negative_class])\n",
        "            anchor = self.load_image(anchor_img)\n",
        "            positive = self.load_image(positive_img)\n",
        "            negative = self.load_image(negative_img)\n",
        "            batch_triplets.append((anchor, positive, negative))\n",
        "        batch_triplets = np.array(batch_triplets)\n",
        "        return batch_triplets[:, 0], batch_triplets[:, 1], batch_triplets[:, 2]\n",
        "\n",
        "    def load_image(self, path):\n",
        "        img = Image.open(path).resize(self.target_size)\n",
        "        img = np.array(img) / 255.0\n",
        "        return img\n",
        "\n",
        "class DynamicUnfreeze(Callback):\n",
        "    def __init__(self, model, accuracy_threshold, layers_to_unfreeze):\n",
        "        super(DynamicUnfreeze, self).__init__()\n",
        "        self.model = model\n",
        "        self.accuracy_threshold = accuracy_threshold\n",
        "        self.layers_to_unfreeze = layers_to_unfreeze\n",
        "        self.patience = 3\n",
        "        self.wait = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_accuracy = logs.get('val_accuracy')\n",
        "        if val_accuracy > self.accuracy_threshold:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.wait = 0\n",
        "                self.unfreeze_layers()\n",
        "\n",
        "    def unfreeze_layers(self):\n",
        "        layers = self.model.layers\n",
        "        unfrozen_layers = sum([layer.trainable for layer in layers])\n",
        "        if unfrozen_layers < len(layers):\n",
        "            for layer in layers[-self.layers_to_unfreeze:]:\n",
        "                layer.trainable = True\n",
        "            print(f\"Unfroze {self.layers_to_unfreeze} more layers. Total unfrozen layers: {unfrozen_layers + self.layers_to_unfreeze}\")\n",
        "\n",
        "# Define the Similarity Model\n",
        "def create_model():\n",
        "    inputs = tf.keras.layers.Input(shape=(160, 160, 3))\n",
        "    x = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")(inputs)\n",
        "    x = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.MaxPool2D()(x)\n",
        "    x = tf.keras.layers.Conv2D(128, 3, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Conv2D(128, 3, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    outputs = MetricEmbedding(128)(x)\n",
        "    return SimilarityModel(inputs, outputs)\n",
        "\n",
        "model = create_model()\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=TripletLoss())\n",
        "\n",
        "# Convert the TripletGenerator to a tf.data.Dataset\n",
        "def triplet_generator_to_dataset(generator):\n",
        "    def gen():\n",
        "        for i in range(len(generator)):\n",
        "            yield generator[i]\n",
        "    return tf.data.Dataset.from_generator(gen,\n",
        "                                          output_signature=(\n",
        "                                              tf.TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32),\n",
        "                                              tf.TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32),\n",
        "                                              tf.TensorSpec(shape=(None, 160, 160, 3), dtype=tf.float32)\n",
        "                                          ))\n",
        "\n",
        "train_generator = TripletGenerator(directory=\"lfw\", batch_size=32)\n",
        "val_generator = TripletGenerator(directory=\"lfw\", batch_size=32)\n",
        "\n",
        "train_dataset = triplet_generator_to_dataset(train_generator).batch(32)\n",
        "val_dataset = triplet_generator_to_dataset(val_generator).batch(32)\n",
        "\n",
        "callback = DynamicUnfreeze(model=model, accuracy_threshold=0.90, layers_to_unfreeze=5)\n",
        "\n",
        "# Use model.fit with the generated datasets and callback\n",
        "model.fit(train_dataset,\n",
        "          validation_data=val_dataset,\n",
        "          epochs=100,\n",
        "          callbacks=[callback])\n"
      ],
      "metadata": {
        "id": "HOQ5Kt1-wq3P",
        "outputId": "c111841b-03bb-477c-b4f8-be6fea7691dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_similarity\n",
            "  Downloading tensorflow_similarity-0.17.1-py3-none-any.whl (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.4/230.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distinctipy (from tensorflow_similarity)\n",
            "  Downloading distinctipy-1.3.4-py3-none-any.whl (26 kB)\n",
            "Collecting nmslib (from tensorflow_similarity)\n",
            "  Downloading nmslib-2.1.1.tar.gz (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (2.0.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-datasets>=4.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (4.9.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (4.66.4)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from tensorflow_similarity) (3.3.4)\n",
            "Collecting umap-learn (from tensorflow_similarity)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets>=4.2->tensorflow_similarity) (0.5.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->tensorflow_similarity) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh->tensorflow_similarity) (1.2.1)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->tensorflow_similarity) (24.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->tensorflow_similarity) (6.0.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->tensorflow_similarity) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->tensorflow_similarity) (2024.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_similarity) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_similarity) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_similarity) (2024.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tensorflow_similarity) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tensorflow_similarity) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tensorflow_similarity) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tensorflow_similarity) (3.1.2)\n",
            "Collecting pybind11<2.6.2 (from nmslib->tensorflow_similarity)\n",
            "  Using cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn->tensorflow_similarity) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn->tensorflow_similarity) (1.2.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn->tensorflow_similarity) (0.58.1)\n",
            "Collecting pynndescent>=0.5 (from umap-learn->tensorflow_similarity)\n",
            "  Downloading pynndescent-0.5.12-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets>=4.2->tensorflow_similarity) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets>=4.2->tensorflow_similarity) (6.4.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets>=4.2->tensorflow_similarity) (4.11.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets>=4.2->tensorflow_similarity) (3.18.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->tensorflow_similarity) (2.1.5)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn->tensorflow_similarity) (0.41.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn->tensorflow_similarity) (1.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->tensorflow_similarity) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets>=4.2->tensorflow_similarity) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets>=4.2->tensorflow_similarity) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets>=4.2->tensorflow_similarity) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets>=4.2->tensorflow_similarity) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn->tensorflow_similarity) (3.5.0)\n",
            "Building wheels for collected packages: nmslib\n",
            "  Building wheel for nmslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nmslib: filename=nmslib-2.1.1-cp310-cp310-linux_x86_64.whl size=13578642 sha256=793282edc7aff1399ccbe5fa08e34c6131721f040a7e5b5e5d747053c2727572\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/1a/5d/4cc754a5b1a88405cad184b76f823897a63a8d19afcd4b9314\n",
            "Successfully built nmslib\n",
            "Installing collected packages: pybind11, distinctipy, nmslib, pynndescent, umap-learn, tensorflow_similarity\n",
            "Successfully installed distinctipy-1.3.4 nmslib-2.1.1 pybind11-2.6.1 pynndescent-0.5.12 tensorflow_similarity-0.17.1 umap-learn-0.5.6\n",
            "Distance metric automatically set to cosine use the distance arg to override.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'lfw'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c5803158398c>\u001b[0m in \u001b[0;36m<cell line: 107>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m                                           ))\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTripletGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lfw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0mval_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTripletGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lfw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-c5803158398c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, batch_size, target_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lfw'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5795f294857943348d4f352a7ea17a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6eb53574ed79461b944ff4751e7597a3",
              "IPY_MODEL_73e8cb6a7774407c8464912a7374d021",
              "IPY_MODEL_73cca73299d241a3aa436d36b4d5b208"
            ],
            "layout": "IPY_MODEL_b7b404e1ad0c4f62bf2d9ae63640abbb"
          }
        },
        "6eb53574ed79461b944ff4751e7597a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f19eaad38eac42baae6aae340cb40e80",
            "placeholder": "​",
            "style": "IPY_MODEL_a3a8690f41b743feaa02d895796dca42",
            "value": "  0%"
          }
        },
        "73e8cb6a7774407c8464912a7374d021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a6abd7096414256baa9e7cd8b84430d",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7ba4218461645f2b4142e1575e67da9",
            "value": 0
          }
        },
        "73cca73299d241a3aa436d36b4d5b208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1625f16e79a949f1beb2735e12b1d042",
            "placeholder": "​",
            "style": "IPY_MODEL_e3a0573538164ff7a7ecb5f0aae29c17",
            "value": " 0/100 [00:00&lt;?, ?it/s]"
          }
        },
        "b7b404e1ad0c4f62bf2d9ae63640abbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f19eaad38eac42baae6aae340cb40e80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3a8690f41b743feaa02d895796dca42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a6abd7096414256baa9e7cd8b84430d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7ba4218461645f2b4142e1575e67da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1625f16e79a949f1beb2735e12b1d042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3a0573538164ff7a7ecb5f0aae29c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac2c4884ca6c4800b7def20ce4427e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98ea69cf41654cb0adc711879d6c2b14",
              "IPY_MODEL_2d4182f1326b41bfa82afc675c0f4be3",
              "IPY_MODEL_fbad2574a7b045e4b0ce57b402166daa"
            ],
            "layout": "IPY_MODEL_f3573b97b0ae4bf6a881f5fc332ce3db"
          }
        },
        "98ea69cf41654cb0adc711879d6c2b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a48cdd11bc640a395aa0a6f9bed9b07",
            "placeholder": "​",
            "style": "IPY_MODEL_d57b338e017c4547b92cd55392d8c281",
            "value": "  0%"
          }
        },
        "2d4182f1326b41bfa82afc675c0f4be3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13055fe7d6784554966b4b23e2ec38cd",
            "max": 183968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9db5738256da4e88aa162ffa2f7cef2b",
            "value": 612
          }
        },
        "fbad2574a7b045e4b0ce57b402166daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ae3d93eb6bc47caa77b84b6690130a0",
            "placeholder": "​",
            "style": "IPY_MODEL_7abf016947f749e0b62d141f6188deda",
            "value": " 612/183968 [06:25&lt;27:42:04,  1.84it/s]"
          }
        },
        "f3573b97b0ae4bf6a881f5fc332ce3db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a48cdd11bc640a395aa0a6f9bed9b07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d57b338e017c4547b92cd55392d8c281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13055fe7d6784554966b4b23e2ec38cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db5738256da4e88aa162ffa2f7cef2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ae3d93eb6bc47caa77b84b6690130a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7abf016947f749e0b62d141f6188deda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}