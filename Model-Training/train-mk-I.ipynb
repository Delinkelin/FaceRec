{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_addons.losses import TripletSemiHardLoss\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicUnfreezeCallback(Callback):\n",
    "    def __init__(self, model, initial_unfreeze_layers, step_unfreeze_layers, threshold, patience):\n",
    "        super(DynamicUnfreezeCallback, self).__init__()\n",
    "        self.model = model\n",
    "        self.initial_unfreeze_layers = initial_unfreeze_layers\n",
    "        self.step_unfreeze_layers = step_unfreeze_layers\n",
    "        self.threshold = threshold\n",
    "        self.patience = patience\n",
    "        self.best_val_accuracy = 0.0\n",
    "        self.unfreeze_count = initial_unfreeze_layers\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_accuracy = logs.get('val_accuracy')\n",
    "        \n",
    "        if val_accuracy > self.best_val_accuracy:\n",
    "            self.best_val_accuracy = val_accuracy\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "        \n",
    "        if self.best_val_accuracy >= self.threshold and self.wait >= self.patience:\n",
    "            self.wait = 0\n",
    "            self.unfreeze_count += self.step_unfreeze_layers\n",
    "            print(f\"Unfreezing additional {self.step_unfreeze_layers} layers.\")\n",
    "            self.unfreeze_layers(self.unfreeze_count)\n",
    "            self.model.compile(optimizer=Adam(1e-4), loss=TripletSemiHardLoss())\n",
    "\n",
    "    def unfreeze_layers(self, num_layers):\n",
    "        for layer in self.model.layers[-num_layers:]:\n",
    "            layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    base_model = tf.keras.applications.InceptionResNetV2(input_shape=(160, 160, 3), include_top=False, pooling='avg')\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    # Freeze all layers initially\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Unfreeze the last `initial_unfreeze_layers` layers\n",
    "    initial_unfreeze_layers = 10\n",
    "    for layer in model.layers[-initial_unfreeze_layers:]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.compile(optimizer=Adam(1e-4), loss=TripletSemiHardLoss())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy data generators for demonstration\n",
    "def generate_triplet(batch_size=32):\n",
    "    while True:\n",
    "        # Generate dummy data\n",
    "        anchor = np.random.rand(batch_size, 160, 160, 3)\n",
    "        positive = np.random.rand(batch_size, 160, 160, 3)\n",
    "        negative = np.random.rand(batch_size, 160, 160, 3)\n",
    "        yield [anchor, positive, negative], np.ones(batch_size)\n",
    "\n",
    "train_generator = generate_triplet()\n",
    "val_generator = generate_triplet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_unfreeze_layers = 10\n",
    "step_unfreeze_layers = 5\n",
    "accuracy_threshold = 0.90\n",
    "patience = 3\n",
    "\n",
    "callbacks = [DynamicUnfreezeCallback(model, initial_unfreeze_layers, step_unfreeze_layers, accuracy_threshold, patience)]\n",
    "\n",
    "model.fit(train_generator, \n",
    "          epochs=50, \n",
    "          steps_per_epoch=100, \n",
    "          validation_data=val_generator, \n",
    "          validation_steps=10, \n",
    "          callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_triplet(data, labels, batch_size=32):\n",
    "    \"\"\"\n",
    "    Generate batches of triplet samples (anchor, positive, negative).\n",
    "    \n",
    "    Args:\n",
    "    data: A numpy array of images.\n",
    "    labels: A numpy array of labels corresponding to the images.\n",
    "    batch_size: Number of triplets to generate in each batch.\n",
    "    \n",
    "    Yields:\n",
    "    A tuple (inputs, targets), where:\n",
    "    - inputs is a list containing [anchor, positive, negative] images.\n",
    "    - targets is an array of ones, used for the triplet loss function.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        anchor_images = []\n",
    "        positive_images = []\n",
    "        negative_images = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            # Randomly select an anchor-positive pair\n",
    "            idx = np.random.randint(0, len(data))\n",
    "            anchor_image = data[idx]\n",
    "            anchor_label = labels[idx]\n",
    "            \n",
    "            # Find positive example (same class as anchor)\n",
    "            pos_idx = np.random.choice(np.where(labels == anchor_label)[0])\n",
    "            positive_image = data[pos_idx]\n",
    "            \n",
    "            # Find negative example (different class from anchor)\n",
    "            neg_idx = np.random.choice(np.where(labels != anchor_label)[0])\n",
    "            negative_image = data[neg_idx]\n",
    "            \n",
    "            # Append the images to their respective lists\n",
    "            anchor_images.append(anchor_image)\n",
    "            positive_images.append(positive_image)\n",
    "            negative_images.append(negative_image)\n",
    "        \n",
    "        # Convert lists to numpy arrays\n",
    "        anchor_images = np.array(anchor_images)\n",
    "        positive_images = np.array(positive_images)\n",
    "        negative_images = np.array(negative_images)\n",
    "        \n",
    "        # Yield a batch of triplet samples and dummy targets\n",
    "        yield [anchor_images, positive_images, negative_images], np.ones(batch_size)\n",
    "\n",
    "# Example usage\n",
    "# Assuming `data` is an array of images and `labels` is an array of corresponding labels\n",
    "# data = np.array([...]) \n",
    "# labels = np.array([...])\n",
    "\n",
    "# Create a generator\n",
    "# train_generator = generate_triplet(data, labels, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New RESPONSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, target_size):\n",
    "    \"\"\"\n",
    "    Load an image from a file and resize it to the target size.\n",
    "    \n",
    "    Args:\n",
    "    image_path (str): Path to the image file.\n",
    "    target_size (tuple): Desired image size (width, height).\n",
    "    \n",
    "    Returns:\n",
    "    np.array: The loaded and resized image.\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize(target_size)\n",
    "    image = img_to_array(image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, main_dir, target_size=(160, 160), batch_size=32):\n",
    "        \"\"\"\n",
    "        Initialize the TripletGenerator.\n",
    "        \n",
    "        Args:\n",
    "        main_dir (str): Path to the main directory containing class subdirectories.\n",
    "        target_size (tuple): Desired image size (width, height).\n",
    "        batch_size (int): Number of triplets per batch.\n",
    "        \"\"\"\n",
    "        self.main_dir = main_dir\n",
    "        self.target_size = target_size\n",
    "        self.batch_size = batch_size\n",
    "        self.class_dirs = [os.path.join(main_dir, d) for d in os.listdir(main_dir) if os.path.isdir(os.path.join(main_dir, d))]\n",
    "        self.class_images = {d: [os.path.join(d, img) for img in os.listdir(d) if img.endswith(('.png', '.jpg', '.jpeg'))] for d in self.class_dirs}\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.class_dirs) * self.batch_size / 3))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        anchors = []\n",
    "        positives = []\n",
    "        negatives = []\n",
    "        \n",
    "        for _ in range(self.batch_size):\n",
    "            anchor_class = random.choice(list(self.class_images.keys()))\n",
    "            positive_class = anchor_class\n",
    "            negative_class = random.choice(list(self.class_images.keys()))\n",
    "\n",
    "            while anchor_class == negative_class:\n",
    "                negative_class = random.choice(list(self.class_images.keys()))\n",
    "\n",
    "            anchor_img = random.choice(self.class_images[anchor_class])\n",
    "            positive_img = random.choice(self.class_images[positive_class])\n",
    "            negative_img = random.choice(self.class_images[negative_class])\n",
    "\n",
    "            anchor_img = load_image(anchor_img, self.target_size)\n",
    "            positive_img = load_image(positive_img, self.target_size)\n",
    "            negative_img = load_image(negative_img, self.target_size)\n",
    "\n",
    "            anchors.append(anchor_img)\n",
    "            positives.append(positive_img)\n",
    "            negatives.append(negative_img)\n",
    "        \n",
    "        return [np.array(anchors), np.array(positives), np.array(negatives)], np.ones(self.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "main_dir = \"path_to_main_directory\"  # Replace with the actual path to your main directory\n",
    "target_size = (160, 160)\n",
    "batch_size = 32\n",
    "\n",
    "# Create the triplet generator\n",
    "train_generator = TripletGenerator(main_dir=main_dir, target_size=target_size, batch_size=batch_size)\n",
    "\n",
    "# Example model\n",
    "model = create_model()  # Assuming create_model() is defined as in the previous example\n",
    "model.compile(optimizer=Adam(1e-4), loss=TripletSemiHardLoss())\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=50, steps_per_epoch=len(train_generator), callbacks=callbacks)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
